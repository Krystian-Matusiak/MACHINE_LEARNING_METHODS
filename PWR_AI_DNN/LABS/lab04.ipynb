{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI1h5v5X4DVb"
      },
      "source": [
        "# Wstęp\n",
        "\n",
        "Na tych zajęciach stworzysz pierwszą sieć wielowarstwową i zapoznasz się z podstawami zadania klasyfikacji obrazów. Dodatkowo zostanie przedstawione narzędzi do wizualizacji procesu uczenia. \n",
        "\n",
        "## Cel ćwiczenia\n",
        "\n",
        "Celem ćwiczenia jest zapoznanie z:\n",
        "*   Wielowarstwowymi sieciami neuronowymi (MLP)\n",
        "*   Podstawami przetwarzania obrazów (ang. Computer Vision)\n",
        "*   Metodami reguralyzacji sieci neuronowych\n",
        "*   Techniką wczesnego zatrzymania uczenia\n",
        "*   Tensorboardem \n",
        "\n",
        "## Warunki zaliczenia\n",
        "\n",
        "W celu zaliczenia ćwiczeń należy uzupełnić wszystkie brakujące elementu kodu, wykonać wszystkie polecenia i wyuczyć opdowiednie warianty modelu.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K593sVbj5Ngn"
      },
      "source": [
        "# Zbiór danych do klasyfikacji obrazów\n",
        "\n",
        "W ramach zadania klasyfikacji obrazów wykorzystamy zbiór [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Zbiór danych składa się z 70.000 obrazów o wymiarach 28x28 pikseli przedstawiających różne typy odzieży w skali szarości. Podobnie jak [MNIST](https://en.wikipedia.org/wiki/MNIST_database), w zbiorze występuje 10 klas.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCg1SztbOENC"
      },
      "source": [
        "### Dane w środowisku Google Colab\n",
        "\n",
        "Uruchomienie notebooka z wykorzystaniem Google Colab powaduje za każdym razem pobranie zbioru danych od nowa. W celu zapisania danych na \"stałe\" możemy wykorzystać Dysk Google, co przyda się nie tylko w kontekście pobrania zbioru, ale również przy zapisywaniu logów.\n",
        "\n",
        "Podłączenie Dysku Google wykonuje się z wykorzystaniem funkcji `google.colab.drive.mount`\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n",
        "```\n",
        "Po wskazaniu ścieżki pod jaką będzie podpięty dysk i wykonaniu komendy, zostaje nam wygenerowany link, gdzie przekazujemy uprawnienia dostępu do danych z dysku dla tego notebooka. Po zaakceptowaniu zostanie nam wygenerowany token, który wklejamy w miejscu wykonania komendy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AazZEdCH2nwz"
      },
      "source": [
        "### Wczytanie danych\n",
        "Do wczytania zbioru danych możemy wykorzystać [`torchvision`](https://pytorch.org/vision/stable/index.html), który zawiara popularne zbiory danych, modele i transformacje danych z dziedziny wizji komputerowej (ang. *computer vision*). \n",
        "\n",
        "Oryginalne dane są zapisane w postaci liczb całkowitych z zakresu 0-255 w postaci [obrazu PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html). Do przeskalowania danych wykorzystamy transformację [`torchvision.transforms.ToTensor`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor). Transformacje danych możemy przekazywać do loadera zbioru danych z `torchvision`. Można przekazać zarówno pojedynczą operację transformacji lub złożyć kilka operacji za pomocą [`torchvision.transforms.Compose`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Compose)\n",
        "\n",
        "**Uwaga** \n",
        "Operacje transform są realizowane w \"locie\" w momencie wywołania `__getitem__`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrKGovm1vrw2"
      },
      "source": [
        "import os\n",
        "\n",
        "from torchvision.datasets import FashionMNIST \n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "path = '/content/drive/MyDrive/lab04/FashionMNIST/'\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "train_data = FashionMNIST(\n",
        "    root=path, \n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "test_data = FashionMNIST(\n",
        "    root=path, \n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh5Q5QfEyMiC"
      },
      "source": [
        "# Wizualizacja danych\n",
        "\n",
        "W odróżnieniu od poprzedniej listy zadań, gdzie ręcznie rysowaliśmy krzywe uczenia i metryki, tym razem wykorzystamy narzędzie do wizualizacji [`tensorboard`](https://www.tensorflow.org/tensorboard). O ile oryginalnie Tensorboard był rozwijany dla Tensorflowa, to i tak możemy wykorzystać w PyTorchu i środowiskiem Google Colab. Funkcje pomocnicze znajdują się w module [`torch.utils.tensorboard`](https://pytorch.org/docs/stable/tensorboard.html). \n",
        "\n",
        "Tensorboard bazuje na logach, które umieszczamy w odpowiednim folderze. Dlatego najpierw zaczniemy od stworzenia takich logów, a dopiero w późniejszym etapie uruchomimy tensorboarda. Zapisywanie logów odbywa się za pomocą klasy [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLNjqkon1621"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "log_dir = '/content/drive/MyDrive/lab04/logs/'\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "writer = SummaryWriter(log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03aqSZsr4g0q"
      },
      "source": [
        "Wyświetlmy teraz kilka obrazów ze zbioru uczącego. Do wyświetlenia siatki zdjęć wykorzystamy funkcję pomocniczą [`torchvision.utils.make_grid`](https://pytorch.org/vision/stable/utils.html#torchvision.utils.make_grid). Do elementów zbioru uczącego, bez nałożonej transformacji, możemy się odwołać za pomocą obiektu `data`. Metoda `make_grid` oczekuje danych w formacie `Batch x Liczba Kanałów x Wysokość x Szerokość`, dlatego musimy dostosować odpowiednio wejście. Pełny kod zdefiniowano poniżej. Następnie przekazujemy utworzony w taki sposób grid, do utworzonej wcześniej instancji klasy `SummaryWriter` za pomocą metody `add_image`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQbPGT0I4gIY"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "images_to_plot = 64\n",
        "img_grid = torchvision.utils.make_grid(\n",
        "    train_data.data[0:images_to_plot].reshape(images_to_plot, 1, 28, 28)\n",
        ")\n",
        "\n",
        "writer.add_image('Train data sample', img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJcoqMMMBRjd"
      },
      "source": [
        "Logi nie są już w tym momencie puste, a więc czas na uruchomienie Tensorboarda. Tensorboard w środowisku Google Colab uruchamiamy za pomocą komend magicznych `%load_ext tensorboard` i `% tensorboard --logdir logs`. \n",
        "W przypadku otrzymania błędu 403 należy również zezwolić przeglądarce na  pliki cookie osób trzecich (ang. *third party cookies*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWBB70_N4fD5"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $log_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaG1XO5n_YQc"
      },
      "source": [
        "# Implementacja architektury MLP\n",
        "\n",
        "Teraz przejdziemy do implementacji architektury wielowarstwowego perceptrona (ang. *multilayer perceptron*, *MLP*). \n",
        "Do zdefiniowania architektury wykorzystaj moduł `torch.nn.Sequential`, przekazując obiekt `OrderDict` zawierający nazwę i warstwy. \n",
        "\n",
        "Przykład\n",
        "```python\n",
        "nn.Sequential(OrderedDict([\n",
        "    ('dense1', nn.Linear(20, 10)),\n",
        "    ('relu1', nn.ReLU()),\n",
        "]))\n",
        "```\n",
        "\n",
        "***Zaimplementuj*** podaną architekturę sieci neuronowej\n",
        "\n",
        "| Nazwa warstwy | Opis |\n",
        "| --- | --- |\n",
        "| flatten | Spłaszczenie obrazu z wymiaru **28x28** na wymiar **784** |\n",
        "| dense1 | Warstwa w pełni połączona z **256** neuronami |\n",
        "| relu1 | Funkcja aktywacji **ReLU** |\n",
        "| dense2 | Warstwa w pełni połączona z **128** neuronami |\n",
        "| relu2 | Funkcja aktywacji **ReLU** |\n",
        "| dense3 | Warstwa w pełni połączona z **10** neuronami |\n",
        "\n",
        "\n",
        "*Metoda inicjalizacji wag i biasów*: domyślna dla warstwy `torch.nn.Linear` (Rozkład jednostajny z zakresem wartości $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$, gdzie $k = \\frac{1}{\\text{in_features}}$)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xL-X-swiFkL"
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "class MLP(nn.Module): \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        ____\n",
        "    )\n",
        "  \n",
        "  def forward(self, x: torch.Tensor):\n",
        "      ____"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYXXYz7qkhQo"
      },
      "source": [
        "Mając zdefiniowaną architekturę i wczytany zbiór danych możemy teraz wyświetlić naszą architekturę w postaci grafu obliczeniowego w Tensorboardzie. W tym celu wykorzystamy poniższy kod."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WewgbnmMkvir"
      },
      "source": [
        "mlp = MLP()\n",
        "\n",
        "writer.add_graph(mlp, input_to_model=train_data[0][0])\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTx8YtYD4UE3"
      },
      "source": [
        "Podobnie jak w liście 2., wykorzystany będzie podział zbioru na trzy części: treningowy, walidacyjny (dev) i testowy. Z tą różnicą, że zbiór testowy pozostawimy bez zmian, aby mieć możliwość porównania się do wyników [innych klasyfikatorow](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/).   \n",
        "\n",
        "***Zaprogramuj*** nowy podział danych:\n",
        "-  Zbiór treningowy podziel na dwie cześci:\n",
        "   - zbiór treninowy/uczący zawierający 54.000 elementy,\n",
        "   - zbiór walidacyjny zawierajcy 6.000 elementów.\n",
        "- Zbiór testowy ma pozostać w oryginalnej formie.\n",
        "- Zachowaj oryginalne proporcje klas w nowoutworzonych zbiorach, tj. dokonaj stratyfikacji. W tym celu możesz wykorzystać metodę `train_test_split` z poprzednich zajęć. Tym razem operację wykonaj na indeksach i utwórz podzbiory używając klasy `torch.utils.data.Subset`. Ustaw `random_state` podziału na $1$.\n",
        "- Utwórz istancje klasy `DataLoader` dla wszystkich części zbiorów. Ustaw wartość parametru `batch_size` na $128$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THsZhO0miEOJ"
      },
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import  DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_train_data(\n",
        "    train_data: torchvision.datasets.FashionMNIST\n",
        ") -> Tuple[Subset, Subset]:\n",
        "    train_idx, dev_idx = train_test_split(\n",
        "        ____,\n",
        "        test_size=___, stratify=____,\n",
        "        random_state=____\n",
        "    )\n",
        "    train = Subset(____)\n",
        "    dev = Subset(____)\n",
        "    return train, dev\n",
        "\n",
        "train, dev = split_train_data(train_data)\n",
        "\n",
        "train_loader = DataLoader(____)\n",
        "dev_loader = DataLoader(____)\n",
        "test_loader = DataLoader(____)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lig0V0ZcqdJY"
      },
      "source": [
        "## Inicjalizacja parametrów sieci\n",
        "Domyślne parametry (w tym metoda incjalizacji wag / biasów) w bibliotece `PyTorch` są dobrane tak, aby dla różnych zadań i architektur dawały optymalne wyniki. W niektórych przypadkach dobranie odpowiedniej metody inicjalizacji wag i biasów do zastosowanej architektury, może usprawnić proces uczenia, przez co poprawić osiągi modelu. Poniżej przedstawiono przykład zastąpienia domyślnej metody inicjalizacji na inicjalizację parametrów z rozkładu normalnego dla pojedynczej warstwy.\n",
        "\n",
        "```python\n",
        "from torch import nn\n",
        "\n",
        "layer = nn.Linear(100, 10)\n",
        "nn.init.normal_(layer.weight, mean=0.0, std=1.0)\n",
        "```\n",
        "\n",
        "Alternatywnie, możemy zmienić inicjalizacje dla kilku warstw, wykorzystując metodę `apply`. \n",
        "```python\n",
        "net = nn.Sequential(\n",
        "      nn.Linear(100, 10),\n",
        "      nn.Linear(10, 1)\n",
        ")\n",
        "\n",
        "def init_layer_params(layer: nn.modules.Module):\n",
        "  if isinstance(layer, nn.Linear):\n",
        "    nn.init.normal_(layer.weight, mean=0.0, std=1.0)\n",
        "    nn.init.normal_(layer.bias, mean=0.0, std=1.0)\n",
        "\n",
        "net.apply(init_layer_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ7EVp9iXxy0"
      },
      "source": [
        "## Generowanie wykresów w Tensorboardzie\n",
        "\n",
        "Logowanie metryk do Tensorboarda odbywa się z wykorzystaniem metody `writer.add_scalar`. Wartości dodajemy pojedynczo. Poniżej przedstawiono przekazanie wartości funkcji straty z kolejnych epok do writera.\n",
        "```python\n",
        "train_loss_values = [0.78, 0.65, 0.5]\n",
        "for epoch_id, train_loss in enumerate(train_loss_values):\n",
        "  writer.add_scalar(\n",
        "    tag='training loss', \n",
        "    scalar_value=train_loss, \n",
        "    global_step=epoch_id+1\n",
        "  )\n",
        "```\n",
        "Nie musimy przekazać wartości osobno dla train i test można umieścić je w jednym obiekcie. Odbywa się to za pomocą metody `writer.add_scalars`. Przykładowe wywołanie dla wartości funkcji straty ze zbioru treningowego i walidacyjnego.\n",
        "```python\n",
        "train_loss_values = [0.78, 0.65, 0.5]\n",
        "dev_loss_values = [0.96, 0.78, 0.79]\n",
        "\n",
        "for epoch_id, (train_loss, dev_loss) in (\n",
        "  enumerate(zip(train_loss_values, dev_loss_values))\n",
        "):\n",
        "    print(train_loss, dev_loss)\n",
        "    writer.add_scalars(\n",
        "      main_tag='loss', \n",
        "      tag_scalar_dict={\n",
        "        'train': train_loss,\n",
        "        'dev': dev_loss\n",
        "      }, \n",
        "      global_step=epoch_id+1\n",
        "    )\n",
        "```\n",
        "\n",
        "Wykresy do Tensorboard dodawane są za pomocą metody `add_figure`. Poniżej zaprezentowano przykład dodania macierzy pomyłek do Tensorboarda.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "cm = confusion_matrix(\n",
        "    y_true=[0, 1, 0, 0], \n",
        "    y_pred=[1, 1, 1, 0]\n",
        ")\n",
        "sns.heatmap(cm, annot=True, figure=fig)\n",
        "writer.add_figure(tag='Confusion matrix', figure=fig)\n",
        "```\n",
        "\n",
        "\n",
        "Wykorzystując funkcję `fit` z poprzednich zajęć ***dodaj***:\n",
        "- Generowanie wykresów krzywej uczenia dla Tensorboarda w zależności od epoki dla zbioru uczącego oraz walidacyjnego\n",
        "- Generowanie wykresów dokładności (ang. *accuracy*) dla Tensorboarda w zależności od epoki dla zbioru uczącego oraz walidacyjnego\n",
        "- Macierz pomyłek dla zbioru testowego po zakończeniu uczenia\n",
        "\n",
        "***Przeprowadź uczenie*** modelu sieci wykorzystyjąc następujące hiperparametry uczenia: \n",
        "\n",
        "- Funkcja straty: ***Entropia krzyżowa***\n",
        "- Wielkość paczki (*min-batch*): ***128***  \n",
        "- Optymalizator: ***Adam*** \n",
        "- Współczynnik uczenia: ***0.01***  \n",
        "- Liczba epok: ***50*** \n",
        "\n",
        "***Dokonaj ewaluacji*** modelu po zakończeniu uczenia na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJvljn8_t-O0"
      },
      "source": [
        "# UMIEŚĆ KOD "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd4Ey0UOZaKZ"
      },
      "source": [
        "# Wczesne zatrzymowanie uczenia (ang. *early stopping*)\n",
        "\n",
        "Jak można zauważyć jakość klasyfikacji na zbiorze walidacyjnym po kilkunastu epokach zaczyna oscylować w takim samym zakresie wartości. Możemy wykorzystać technikę wczesnego zatrzymania, w momencie kiedy funkcja straty na zbiorze walidacyjnym przestaje maleć, zatrzymywany jest cały proces. Liczba epok po których nie dochodzi do poprawy wartości funkcji kosztu, i zatrzymywany jest proces uczenia, jest kontrolowany hiperparametrem cierpliwości (ang. *patience*).\n",
        "\n",
        "Do zaimplementowania tej techniki potrzebne nam będzie zapisywanie modelu po każdej epoce w której doszło do poprawy jakości modelu. W tym celu używamy metody `torch.save`, który zapisuje zadany mu obiekt w postaci pythonowego pickla. W bibliotece PyTorch dostęp do wyuczalnych parametry mamy za pomocą `state_dict`. `state_dict` jest to pythonowy słownik, który mapuje każdą warstwę do tensora jej parametrów. Jeżeli chcemy użyć modelu do inferencji wystarczy, że zapiszemy wyłącznie parametry modelu. W przypadku kiedy chcemy mieć możliwość douczenia modelu w późniejszym momencie musimy również zapisać `state_dict` z wykorzystanego optymalizatora. Do nas należy decyzja co chcemy zapisać, więc oprócz samych parametrów warto zapisać numer epoki, wartości funkcji kosztu, hiperparametry modelu czy optymalizatora.\n",
        "\n",
        "Przykładowy kod do zapisywania modelu\n",
        "```python\n",
        "torch.save(\n",
        "    obj={\n",
        "      'epoch': epoch,\n",
        "      'loss': loss,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'model_args': model_args,\n",
        "      'optim_args': optim_args\n",
        "    },\n",
        "    f=output_path\n",
        ")\n",
        "```\n",
        "\n",
        " Wczytanie modelu składa się z kilku kroków:\n",
        " - Wczytujemy zapisany przez nas punkt kontrolny (ang. *checkpoint*)\n",
        " - Inicjalizujemy model i optymalizator od nowa.\n",
        " - Ładujemy obiekt `state_dict` odpowiednio do modelu i optymalizatora\n",
        "\n",
        "Przykładowy kod do wczytania modelu.\n",
        "```python\n",
        "checkpoint = torch.load(output_path)\n",
        "\n",
        "model = ModelCls(**checkpoint['model_args'])\n",
        "optimizer = OptimazerCls(**checkpoint['optim_args'])\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzpaIS2VZh4X"
      },
      "source": [
        "**Zaimplementuj technikę wczesnego zatrzymania** wraz z zapisywaniem punktów kontrolnych modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ThMvWPyaExl"
      },
      "source": [
        "***Zastosuj*** dwie wybrane techniki reguralyzacji sieci (L1, L2, Dropout). Sprawdź czy poprawiły one wyniki Twojego modelu na zbiorze testowym. Dodaj wykresy do Tensorboarda, dokonaj porównania i podsumowania wyników\n",
        "\n",
        "**UWAGA** W przypadku zastosowania metody optymalizacji `Adam` i regularyzacji `L2` należy zastosować optymalizator `AdamW`. Więcej szczegółów można znaleźć w publikacji autorów optymalizatora `AdamW` https://arxiv.org/abs/1711.05101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y538S9uuSbv"
      },
      "source": [
        "# UMIEŚĆ KOD "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}